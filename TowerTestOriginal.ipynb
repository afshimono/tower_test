{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d75238-88c4-480b-9246-b0fd15e0bbc4",
   "metadata": {},
   "source": [
    "## Brief Problem Description\n",
    "Given an input file which has the location of a person based on cellular tower triangulation, generate an output with 2 columns,\n",
    "containing one row for each input line, tagging it as a tower jump (erroneous localization) and a confidence level (expressed as a number between 0 and 1)\n",
    "\n",
    "## References\n",
    "\n",
    "https://www.tinybird.co/blog-posts/anomaly-detection\n",
    "\n",
    "https://medium.com/analytics-vidhya/removing-outliers-understanding-how-and-what-behind-the-magic-18a78ab480ff\n",
    "\n",
    "\n",
    "## Solution (TLDR)\n",
    "\n",
    "1. if lat and lon are zero -> flag as jump ( I hope John Doe is not visiting [Null Island](https://en.wikipedia.org/wiki/Null_Island) )\n",
    "2. order the full dataset by datetime\n",
    "3. calculate diff in minutes between points\n",
    "4. calculate quartile of 80% in min (this was selected by me at random, it will be a variable in case we want to play with it)\n",
    "5. group measurements in cluster when the time in minutes between rows is below the 80% quartile\n",
    "6. remove outliers, calculate z value for lat and lon, any row that has either lon or lat below z +- 2 std, will be flagged as jump\n",
    "7. calculate confidence as how close the lat and lon are to z if it is not a jump, or 1 - diff if it was flagged as jump\n",
    "8. reorder output based on page and item number\n",
    "\n",
    "## This Notebook\n",
    "... was used when attempting to extract relevant data from the sample to write the solution, so it is not necessarily in an order\n",
    "to help understand the solution, but in the order the data was being analysed.\n",
    "\n",
    "## Initial Assumptions\n",
    "Given the nature of the problem, which does not appear to have an exact solution that can be solved by a formal algorithm (the request to use a \"confidence level\" in the output gave that hint), we will try some statistical approach.\n",
    "1- This appears to be a particular case of anomaly detection, and it will be handled as such\n",
    "2- Many simplifications will be done given the limitations of time\n",
    "3- A Script will be provided that can be called on the command line to produce the output, given the input is in the same format that the one provided in the challenge description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb2b4e-2d64-4897-b4cb-61c31a78de84",
   "metadata": {},
   "source": [
    "### Loading input\n",
    "First load the input file and check the content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7acf01-8817-4903-adab-f20214ac16c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/03/dk_48dlx61z4x4bw69x0bymc0000gn/T/ipykernel_31451/2879042676.py:6: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(INPUT_PATH)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Number</th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Local Date &amp; Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>CellType</th>\n",
       "      <th>UTCDateTime</th>\n",
       "      <th>Time Zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Voice</td>\n",
       "      <td>1/2/22 20:14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1/3/22 8:50</td>\n",
       "      <td>41.12475</td>\n",
       "      <td>-73.491694</td>\n",
       "      <td>\\\"New Canaan\\</td>\n",
       "      <td>Western Connecticut</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>United States</td>\n",
       "      <td>Voice</td>\n",
       "      <td>1/3/22 13:50</td>\n",
       "      <td>America/New_York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1/3/22 10:17</td>\n",
       "      <td>40.85628</td>\n",
       "      <td>-73.522710</td>\n",
       "      <td>\\\"East Norwich\\</td>\n",
       "      <td>Nassau</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>Voice</td>\n",
       "      <td>1/3/22 15:17</td>\n",
       "      <td>America/New_York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Voice</td>\n",
       "      <td>1/3/22 15:17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1/3/22 10:17</td>\n",
       "      <td>40.85628</td>\n",
       "      <td>-73.522710</td>\n",
       "      <td>\\\"East Norwich\\</td>\n",
       "      <td>Nassau</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>Voice</td>\n",
       "      <td>1/3/22 15:17</td>\n",
       "      <td>America/New_York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Page Number  Item Number Local Date & Time  Latitude  Longitude  \\\n",
       "0          1.0          1.0               NaN   0.00000   0.000000   \n",
       "1          1.0          2.0       1/3/22 8:50  41.12475 -73.491694   \n",
       "2          1.0          3.0      1/3/22 10:17  40.85628 -73.522710   \n",
       "3          1.0          4.0               NaN   0.00000   0.000000   \n",
       "4          1.0          5.0      1/3/22 10:17  40.85628 -73.522710   \n",
       "\n",
       "              City               County        State        Country CellType  \\\n",
       "0              NaN                  NaN          NaN            NaN    Voice   \n",
       "1    \\\"New Canaan\\  Western Connecticut  Connecticut  United States    Voice   \n",
       "2  \\\"East Norwich\\               Nassau     New York  United States    Voice   \n",
       "3              NaN                  NaN          NaN            NaN    Voice   \n",
       "4  \\\"East Norwich\\               Nassau     New York  United States    Voice   \n",
       "\n",
       "    UTCDateTime         Time Zone  \n",
       "0  1/2/22 20:14               NaN  \n",
       "1  1/3/22 13:50  America/New_York  \n",
       "2  1/3/22 15:17  America/New_York  \n",
       "3  1/3/22 15:17               NaN  \n",
       "4  1/3/22 15:17  America/New_York  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "INPUT_PATH = \"TowerJumpsDataSet_CarrierRecords.csv\"\n",
    "# INPUT_PATH = \"4245337_CarrierRecords.csv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf21854-5eb0-4fd7-a0df-399ec453ec34",
   "metadata": {},
   "source": [
    "Now, we look at all values in the columns to try to get a perspective of how this data is distributed.\n",
    "By running `describe`, nothing particular draws our attention, except that the page number and item number do not seem relevant to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f512a96-1265-4a27-844a-43f96865ab7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Number</th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>136857.000000</td>\n",
       "      <td>136857.000000</td>\n",
       "      <td>136857.000000</td>\n",
       "      <td>136857.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7572.195766</td>\n",
       "      <td>38313.405474</td>\n",
       "      <td>25.414618</td>\n",
       "      <td>-51.196611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4687.652228</td>\n",
       "      <td>31070.458019</td>\n",
       "      <td>18.233707</td>\n",
       "      <td>35.520171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-112.066545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3529.000000</td>\n",
       "      <td>10790.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-73.974291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7378.000000</td>\n",
       "      <td>30533.000000</td>\n",
       "      <td>38.235047</td>\n",
       "      <td>-73.491700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11022.000000</td>\n",
       "      <td>65465.000000</td>\n",
       "      <td>41.124800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15746.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>45.300000</td>\n",
       "      <td>80.260230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Page Number    Item Number       Latitude      Longitude\n",
       "count  136857.000000  136857.000000  136857.000000  136857.000000\n",
       "mean     7572.195766   38313.405474      25.414618     -51.196611\n",
       "std      4687.652228   31070.458019      18.233707      35.520171\n",
       "min         1.000000       1.000000       0.000000    -112.066545\n",
       "25%      3529.000000   10790.000000       0.000000     -73.974291\n",
       "50%      7378.000000   30533.000000      38.235047     -73.491700\n",
       "75%     11022.000000   65465.000000      41.124800       0.000000\n",
       "max     15746.000000   99999.000000      45.300000      80.260230"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab69b76-a7b6-429e-b062-9ebc6447037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137057"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e20f2ca-e3bc-4ceb-80a2-65c92a6c5e07",
   "metadata": {},
   "source": [
    "Time zone appears to have 2 exotic values: Etc and Asia. Let´s look a bit closer at what data they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6abda81a-d705-478a-b4cc-273b6eb4449e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time Zone\n",
       "America/New_York                93686\n",
       "America/Denver                    746\n",
       "America/Kentucky/Louisville       377\n",
       "America/Indiana/Indianapolis      118\n",
       "America/Chicago                    33\n",
       "America/Detroit                     3\n",
       "Asia/Kolkata                        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Time Zone\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321b7f9-3def-43b3-849b-4994312e5d32",
   "metadata": {},
   "source": [
    "Asia has only 5 entries, the location (lat and lon) might be correct, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ff5bcd-a4db-492f-9eca-13fcb201f6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Number</th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Local Date &amp; Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>CellType</th>\n",
       "      <th>UTCDateTime</th>\n",
       "      <th>Time Zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Page Number, Item Number, Local Date & Time, Latitude, Longitude, City, County, State, Country, CellType, UTCDateTime, Time Zone]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Time Zone\"]==\"Asia/Bishkek\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ec9de-c0e7-4fe9-86cf-a26e73875dda",
   "metadata": {},
   "source": [
    "ETC has no good value for lat and lon, so this one can possibly be a case for automatically flagging it as a jump with high confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a16abc-f92b-49ad-8c02-c209a84ecdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Number</th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Local Date &amp; Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>CellType</th>\n",
       "      <th>UTCDateTime</th>\n",
       "      <th>Time Zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Page Number, Item Number, Local Date & Time, Latitude, Longitude, City, County, State, Country, CellType, UTCDateTime, Time Zone]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Time Zone\"]==\"Etc/GMT\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d795522a-818f-4b0e-9c34-43e226643a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Latitude  Longitude\n",
       "count       0.0        0.0\n",
       "mean        NaN        NaN\n",
       "std         NaN        NaN\n",
       "min         NaN        NaN\n",
       "25%         NaN        NaN\n",
       "50%         NaN        NaN\n",
       "75%         NaN        NaN\n",
       "max         NaN        NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Time Zone\"]==\"Etc/GMT\"][[\"Latitude\",\"Longitude\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b763bc81-61d7-4a41-a1f3-09e8cd577fcb",
   "metadata": {},
   "source": [
    "Country is either USA or NaN, so nothing extraordinary here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d5d8804-41e0-4d55-b64b-ba11503d8bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "United States    94965\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d028d1-6672-4b6d-b333-3f9b5ecd4b55",
   "metadata": {},
   "source": [
    "States look OK, except for the `unknown` value. However, some of the `unknown` have non zero lat/lon location, so this alone is possibly not a good indicator of a jump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22ee71e-a690-4e9e-bec0-2e5f712795b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State\n",
       "Connecticut       36757\n",
       "New York          30360\n",
       "Florida           21845\n",
       "New Jersey          951\n",
       "Kentucky            931\n",
       "Pennsylvania        828\n",
       "South Carolina      533\n",
       "North Carolina      437\n",
       "Utah                408\n",
       "Massachusetts       388\n",
       "Georgia             367\n",
       "New Mexico          299\n",
       "Virginia            224\n",
       "West Virginia       175\n",
       "Indiana             131\n",
       "Delaware             88\n",
       "Maryland             60\n",
       "Vermont              53\n",
       "Colorado             34\n",
       "Tennessee            24\n",
       "Rhode Island         21\n",
       "Missouri             19\n",
       "Nebraska             10\n",
       "Maine                 6\n",
       "Iowa                  6\n",
       "Michigan              3\n",
       "unknown               2\n",
       "Ohio                  2\n",
       "Wisconsin             2\n",
       "Wyoming               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"State\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dd01c51-0df6-4350-a026-c2ab6679f645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Number</th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Local Date &amp; Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>CellType</th>\n",
       "      <th>UTCDateTime</th>\n",
       "      <th>Time Zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>43.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>3/13/22 20:38</td>\n",
       "      <td>26.638330</td>\n",
       "      <td>80.260230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>Voice</td>\n",
       "      <td>3/13/22 15:08</td>\n",
       "      <td>Asia/Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>46.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>3/19/22 3:22</td>\n",
       "      <td>26.702682</td>\n",
       "      <td>80.036514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>United States</td>\n",
       "      <td>Voice</td>\n",
       "      <td>3/18/22 21:52</td>\n",
       "      <td>Asia/Kolkata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Page Number  Item Number Local Date & Time   Latitude  Longitude City  \\\n",
       "664         43.0        665.0     3/13/22 20:38  26.638330  80.260230  NaN   \n",
       "703         46.0        704.0      3/19/22 3:22  26.702682  80.036514  NaN   \n",
       "\n",
       "      County    State        Country CellType    UTCDateTime     Time Zone  \n",
       "664  unknown  unknown  United States    Voice  3/13/22 15:08  Asia/Kolkata  \n",
       "703  unknown  unknown  United States    Voice  3/18/22 21:52  Asia/Kolkata  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"State\"]==\"unknown\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "443b3127-3a9d-4bf6-acc6-9bae3b516355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.670506</td>\n",
       "      <td>80.148372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.045504</td>\n",
       "      <td>0.158191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>26.638330</td>\n",
       "      <td>80.036514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.654418</td>\n",
       "      <td>80.092443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.670506</td>\n",
       "      <td>80.148372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.686594</td>\n",
       "      <td>80.204301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.702682</td>\n",
       "      <td>80.260230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Latitude  Longitude\n",
       "count   2.000000   2.000000\n",
       "mean   26.670506  80.148372\n",
       "std     0.045504   0.158191\n",
       "min    26.638330  80.036514\n",
       "25%    26.654418  80.092443\n",
       "50%    26.670506  80.148372\n",
       "75%    26.686594  80.204301\n",
       "max    26.702682  80.260230"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"State\"]==\"unknown\"][[\"Latitude\",\"Longitude\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829159c-0f4a-4018-8c4e-3f275e9b7f1e",
   "metadata": {},
   "source": [
    "Record Type does not seem to give valuable information for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2808cd2b-a2e1-4455-a47c-ba87140656c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Record Type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/Weblogiko/tower_test/venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Record Type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRecord Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[0;32m~/Projects/Weblogiko/tower_test/venv/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Projects/Weblogiko/tower_test/venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Record Type'"
     ]
    }
   ],
   "source": [
    "df[\"Record Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81ebbc-c037-4199-9870-62dd9461833a",
   "metadata": {},
   "source": [
    "Datetime can be used to gather interesting information, like the distribution of the records over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3930e90-fbe3-4eff-ac7e-8a4a402517cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Datetime\"] = pd.to_datetime(df[\"Local Date & Time\"], format=\"%m/%d/%y %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f49870-b65e-442a-a07c-0590cb1359bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[\"Datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9b80a-baea-4908-9701-6fe208197b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Datetime\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97331d5c-11ea-4811-9212-b8b540f8c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_df = df[df[\"Datetime\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e1cb5-6515-43ed-9210-bcc9b7833259",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_datetime_df = df[df[\"Datetime\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643d3a9-bd76-43d4-a747-410ad00b0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_datetime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5da3da-94f4-4b08-80c7-efbc6db56372",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d4c41-961a-4b82-aef7-93f8edc165b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DatetimeDelta\"] =  df[\"Datetime\"] - df[\"Datetime\"].shift(1)\n",
    "df[\"DatetimeDelta\"] = df[\"DatetimeDelta\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b61e2-748c-4289-8ade-1de3ea70003e",
   "metadata": {},
   "source": [
    "## DatetimeDeltaMinutes\n",
    "This is an interesting metric because it shows the distribution of data.\n",
    "In practise, this means that the effect that many records with the same location happen in a short period of time, in bursts,\n",
    "is very common in this dataset.\n",
    "I do not have any expertise in cellular tower location algorithms, but statiscally, we will consider that if a position is reported\n",
    "repeatedly, this will mean it is more relevant and has a higher chance of being correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d91ceb-ca74-4511-8a95-ea8dc4a45eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DatetimeDeltaMinutes\"] = df[\"DatetimeDelta\"].apply(lambda x: (x.total_seconds())/60 if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c855987-0c12-4c68-bca1-56e8be57ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Datetime\",\"DatetimeDelta\",\"DatetimeDeltaMinutes\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8266ca-714d-413b-ac10-597cb28047c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DatetimeDeltaMinutes\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c8d06-48ff-4f62-a83a-c5fdb808197b",
   "metadata": {},
   "source": [
    "Now we can visualize that the vast majority of interval between measurements is actually pretty small, and also that\n",
    "the 90% quartile is 16 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe2d41-bc5a-402f-928b-0c7e9ce28257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(data=df[[\"Datetime\",\"DatetimeDeltaMinutes\"]], x=\"DatetimeDeltaMinutes\",binwidth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7c4a3-b348-4ebb-9c1e-b4d0d20dc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DatetimeDeltaMinutes\"].quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6eefa5-6fb8-4010-a61b-7e839adda01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quartile_limit = df[\"DatetimeDeltaMinutes\"].quantile(0.8)\n",
    "quartile_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba373e-a90e-40e8-8132-805532f5be58",
   "metadata": {},
   "source": [
    "## Intuition and Main code\n",
    "Reading the references regarding anomaly detection, and taking into account the pecualirity of ths data set regarding the\n",
    "\"burst\" effect (there are many measurements very close to each other in time, and those groups are separated by a large amount of time), instead of using a fixed time window to calculate the Z value each point and judge if a point is an anomaly or not,\n",
    "we will instead cluster the points together when they happen close to each other in time.\n",
    "\n",
    "The idea is that if a measurement happens in a single geo location and there are no conflicting measurements at the same time, we do not have a lot of reason to believe it is faulty, but if many measurements happen with different locations and close to each other in terms of time, the chance that some of them are faulty is higher.\n",
    "We have one specific case that is always tagged as faulty which is lat and lon = (0,0).\n",
    "\n",
    "There were some parameter tuning made while looking at the results to optimize the desired behavior.\n",
    "1. the value used to classify a point as either faulty or not was 1 standard deviation. This is lower than the suggested value of 2 because we want to have one tagged as correct and many different tagged as faulty when there are conflicts.\n",
    "2. the upper and lower bounds used to remove outliers were 15 quantile and 85 quantile, because they had better result than 25 and 75.\n",
    "3. the calculation of accuracy was done manually, following the logic that z values close to 0 should have higher accuracy, whereas values higher than 2 should have very low accuracy. At the same time, if we flag a point as faulty and the z value is really big, accuracy should be higher.\n",
    "4. the calculation of difference between locations was done using simple euclidean distance instead of using proper geolocation calculation. This was required to calculate the Z Score for each point.\n",
    "\n",
    "Another important aspect we took into account is that faulty measurements should be the exception, not the rule, otherwise this method of geolocation would make sense. In other words, there should be generally more correct measurements than faulty ones.\n",
    "\n",
    "With those concepts in mind, the following code was written to calculate the Z Score to each point and tag it as `tower_jump` = y or n.\n",
    "\n",
    "**Note that the code below will run only on 1000 entries. This was done on purpose to just validate the code. The full version of the code is available in the `main.py` file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ec5dd-6033-4119-aa8f-9cd7b6410906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class LocationPoint:\n",
    "    def __init__(self, location:Tuple[float,float], page:int, item:int, date_and_time:str):\n",
    "        self.location = location\n",
    "        self.page = page\n",
    "        self.item = item\n",
    "        self.date_and_time = date_and_time\n",
    "        self.z_dist = None\n",
    "        self.tower_jump = None\n",
    "        self.accuracy = None\n",
    "        self.cluster_avg = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Location: {self.location} \\n Date_and_time: {self.date_and_time} \\n Page: {self.page} \\n Item: {self.item} \\n Z_dist: {self.z_dist} \\n Tower_jump: {self.tower_jump} \\n Accuracy: {self.accuracy} \\n Cluster AVG: {self.cluster_avg})\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"page\":self.page,\n",
    "            \"item\":self.item,\n",
    "            \"date_and_time\":self.date_and_time,\n",
    "            \"tower_jump\": self.tower_jump,\n",
    "            \"accuracy\": \"{:.2f}\".format(float(self.accuracy))\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def from_row(input):\n",
    "        lat = input[\"Latitude\"]\n",
    "        lon = input[\"Longitude\"]\n",
    "        if isinstance(lat, np.float64):\n",
    "            lat = float(lat)\n",
    "        if isinstance(lon, np.float64):\n",
    "            lon = float(lon)\n",
    "        return LocationPoint((lat,lon),input[\"Page Number\"],input[\"Item Number\"],input[\"Local Date & Time\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04634354-22f3-48f9-ad94-83b526bdf422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_from_z(z_score:float)->int:\n",
    "    if abs(z_score) <= 0.5:\n",
    "        return 80 + (0.5 - abs(z_score))*38\n",
    "    elif abs(z_score) <= 1:\n",
    "        return 50 + (1 - abs(z_score))*30\n",
    "    elif abs(z_score) <= 2:\n",
    "        return 30 + (2 - abs(z_score))*10\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd798183-8103-4259-8839-383aa54471c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mean_std_and_z_scores(input_list:List[LocationPoint]) -> List[LocationPoint]:\n",
    "\n",
    "    all_zeros = all([item.location == (0,0) for item in input_list])\n",
    "\n",
    "    if not all_zeros:\n",
    "        lat_list = []\n",
    "        lon_list = []\n",
    "        for item in input_list:\n",
    "            if item.location != (0,0):\n",
    "                lat_list.append(item.location[0])\n",
    "                lon_list.append(item.location[1])\n",
    "    \n",
    "        #print(f\"LAT {lat_list} LON {lon_list}\")\n",
    "        # remove outliers\n",
    "        q1_lat = np.percentile(lat_list, 15)\n",
    "        q3_lat = np.percentile(lat_list, 85)\n",
    "        q1_lon = np.percentile(lon_list, 15)\n",
    "        q3_lon = np.percentile(lon_list, 85)\n",
    "    \n",
    "        # print(f\"PERCENTILE LAT {q1_lat} {q3_lat} LON {q1_lon} {q3_lon}\")\n",
    "    \n",
    "        clean_lat_list = [item for item in lat_list if item >= q1_lat and item <= q3_lat]\n",
    "        clean_lon_list = [item for item in lon_list if item >= q1_lon and item <= q3_lon]\n",
    "        #print(f\"CLEAN LAT {clean_lat_list} LON {clean_lon_list}\")\n",
    "    \n",
    "        lat_avg = np.average(clean_lat_list)\n",
    "        lon_avg = np.average(clean_lon_list)\n",
    "    \n",
    "        std_lat = np.std(clean_lat_list)\n",
    "        std_lon = np.std(clean_lon_list)\n",
    "        #print(f\"STD {std_lat} {std_lon}\")\n",
    "    \n",
    "        total_std = np.sqrt(np.sum(np.power([std_lat,std_lon],2)))\n",
    "    \n",
    "        #print(f\"TOTAL STD {total_std}\")\n",
    "\n",
    "    for item in input_list:\n",
    "        if item.location == (0,0):\n",
    "            item.z_dist = -10\n",
    "            item.tower_jump = \"y\"\n",
    "            item.accuracy = 99\n",
    "        else:\n",
    "            item.z_dist = np.linalg.norm(np.subtract(list(item.location),[lat_avg,lon_avg])) / total_std if total_std > 0 else 0\n",
    "            #print(f\"Z_DIST {item.z_dist}\")\n",
    "            item.tower_jump = \"y\" if abs(item.z_dist) > 1 else \"n\"\n",
    "            item.accuracy = calculate_accuracy_from_z(item.z_dist) if item.tower_jump == \"n\" else (100 - calculate_accuracy_from_z(item.z_dist))\n",
    "        item.cluster_avg = (lat_avg,lon_avg) if not all_zeros else None\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6409235b-ec80-4fae-8a25-542a3d1a8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "point_dict_list = []\n",
    "current_cluster = [LocationPoint.from_row(df.iloc[0])]\n",
    "for index, row in islice(df.iterrows(), 1, 1000):\n",
    "    if row[\"DatetimeDeltaMinutes\"] < 5:\n",
    "        current_cluster.append(LocationPoint.from_row(row))\n",
    "    else:\n",
    "        # print(f\" CLUSTER TO ANALYSE {current_cluster}\")\n",
    "        point_list = calculate_mean_std_and_z_scores(current_cluster)\n",
    "        point_dict_list += [item.to_dict() for item in point_list]\n",
    "        current_cluster = [LocationPoint.from_row(row)]\n",
    "if len(current_cluster)>0:\n",
    "    point_list = calculate_mean_std_and_z_scores(current_cluster)\n",
    "    point_dict_list += [item.to_dict() for item in point_list]\n",
    "    current_cluster = [LocationPoint.from_row(row)]\n",
    "#print(f\"FINAL LIST {point_dict_list}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e778e99-3b70-46fe-a03b-5b84a5f587df",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(point_dict_list)\n",
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c340c-f5e5-45d1-a719-9fe0e52cadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.sort_values(by=[\"page\",\"item\"],ascending=[True, True])\n",
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09103639-c153-4a46-85b5-e9dee88ba4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b3bb7-29dc-4a9e-bc85-dd7641a6dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf289392-7ff5-4291-99b2-340e7cf62edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
